{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Source/fastICA_0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Source/fastICA_0.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def sym_decorrelation(W):\n",
    "    \"\"\" Symmetric decorrelation \"\"\"\n",
    "    K = np.dot(W, W.T)\n",
    "    s, u = np.linalg.eigh(K) \n",
    "    W = (u @ np.diag(1.0/np.sqrt(s)) @ u.T) @ W\n",
    "    return W\n",
    "\n",
    "def g_logcosh(wx,alpha):\n",
    "    \"\"\"derivatives of logcosh\"\"\"\n",
    "    return np.tanh(alpha * wx)\n",
    "def gprime_logcosh(wx,alpha):\n",
    "    \"\"\"second derivatives of logcosh\"\"\"\n",
    "    return alpha * (1-np.square(np.tanh(alpha*wx)))\n",
    "# exp\n",
    "def g_exp(wx,alpha):\n",
    "    \"\"\"derivatives of exp\"\"\"\n",
    "    return wx * np.exp(-np.square(wx)/2)\n",
    "def gprime_exp(wx,alpha):\n",
    "    \"\"\"second derivatives of exp\"\"\"\n",
    "    return (1-np.square(wx)) * np.exp(-np.square(wx)/2)\n",
    "\n",
    "def fastICA_0(X, f,alpha=None, n_comp=None,maxit=200, tol=1e-04):\n",
    "    \"\"\"FastICA algorithm for several units\"\"\"\n",
    "    n,p = X.shape\n",
    "    #check if n_comp is valid\n",
    "    if n_comp is None:\n",
    "        n_comp = min(n,p)\n",
    "    elif n_comp > min(n,p):\n",
    "        print(\"n_comp is too large\")\n",
    "        n_comp = min(n,p)\n",
    "        \n",
    "    #centering\n",
    "    #by subtracting the mean of each column of X (array).\n",
    "    X = preprocessing.scale(X,axis = 0,with_std=False)\n",
    "    X = X.T\n",
    "\n",
    "    #whitening\n",
    "    svd = np.linalg.svd(X @ (X.T) / n)\n",
    "    k = np.diag(1/np.sqrt(svd[1])) @ (svd[0].T)\n",
    "    k = k[:n_comp,:] \n",
    "    X1 = k @ X\n",
    "\n",
    "    # initial random weght vector\n",
    "    w_init = np.random.normal(size=(n_comp, n_comp))\n",
    "    W = sym_decorrelation(w_init)\n",
    "    lim = 1\n",
    "    it = 0\n",
    "    \n",
    "    \n",
    "    # The FastICA algorithm\n",
    "    if f == \"logcosh\":\n",
    "        while lim > tol and it < maxit :\n",
    "            wx = W @ X1\n",
    "            gwx = g_logcosh(wx,alpha)\n",
    "            g_wx = gprime_logcosh(wx,alpha)\n",
    "            W1 = np.dot(gwx,X1.T)/X1.shape[1] - np.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "            W1 = sym_decorrelation(W1)\n",
    "            it = it +1\n",
    "            lim = np.max(np.abs(np.abs(np.diag(W1 @ W.T)) - 1.0))\n",
    "            W = W1\n",
    "\n",
    "        S = W @ X1\n",
    "        A = np.linalg.inv(W @ k)\n",
    "        X_re = A @ S\n",
    "        return{'X':X1.T,'X_re':X_re.T,'A':A.T,'S':S.T}\n",
    "\n",
    "    elif f == \"exp\":\n",
    "        while lim > tol and it < maxit :\n",
    "            wx = W @ X1\n",
    "            gwx = g_exp(wx,alpha)\n",
    "            g_wx = gprime_exp(wx,alpha)\n",
    "            W1 = np.dot(gwx,X1.T)/X1.shape[1] - np.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "            W1 = sym_decorrelation(W1)\n",
    "            it = it +1\n",
    "            lim = np.max(np.abs(np.abs(np.diag(W1 @ W.T)) - 1.0))\n",
    "            W = W1\n",
    "\n",
    "        S = W @ X1\n",
    "        A = np.linalg.inv(W @ k)\n",
    "        X_re = A @ S\n",
    "        return{'X':X1.T,'X_re':X_re.T,'A':A.T,'S':S.T}\n",
    "\n",
    "    else:\n",
    "        print(\"doesn't support this approximation negentropy function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Source/fastICA_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Source/fastICA_1.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sym_decorrelation(W):\n",
    "    \"\"\" Symmetric decorrelation \"\"\"\n",
    "    K = np.dot(W, W.T)\n",
    "    s, u = np.linalg.eigh(K) \n",
    "    W = (u @ np.diag(1.0/np.sqrt(s)) @ u.T) @ W\n",
    "    return W\n",
    "\n",
    "def fastICA_1(X, f,alpha=None, n_comp=None,maxit=200, tol=1e-04):\n",
    "    \"\"\"FastICA algorithm for several units\"\"\"\n",
    "    n,p = X.shape\n",
    "    #check if n_comp is valid\n",
    "    if n_comp is None:\n",
    "        n_comp = min(n,p)\n",
    "    elif n_comp > min(n,p):\n",
    "        print(\"n_comp is too large\")\n",
    "        n_comp = min(n,p)\n",
    "        \n",
    "    #centering\n",
    "    #by subtracting the mean of each column of X (array).\n",
    "    X = X - X.mean(axis=0)[None,:]\n",
    "    X = X.T\n",
    "\n",
    "    #whitening\n",
    "    svd = np.linalg.svd(X @ (X.T) / n)\n",
    "    k = np.diag(1/np.sqrt(svd[1])) @ (svd[0].T)\n",
    "    k = k[:n_comp,:] \n",
    "    X1 = k @ X\n",
    "    del X\n",
    "    \n",
    "    # approximation negentropy function\n",
    "    if f == \"logcosh\":\n",
    "        def g(wx,alpha):\n",
    "            return np.tanh(alpha * wx)\n",
    "        def gprime(wx,alpha):\n",
    "            return alpha * (1-np.square(np.tanh(alpha*wx)))\n",
    "    elif f == \"exp\":\n",
    "        def g(wx,alpha):\n",
    "            return wx * np.exp(-np.square(wx)/2)\n",
    "        def gprime(wx,alpha):\n",
    "            return (1-np.square(wx)) * np.exp(-np.square(wx)/2)\n",
    "    else:\n",
    "        print(\"doesn't support this approximation negentropy function\")\n",
    "               \n",
    "    # initial random weght vector\n",
    "    w_init = np.random.normal(size=(n_comp, n_comp))\n",
    "    W = sym_decorrelation(w_init)\n",
    "\n",
    "    lim = 1\n",
    "    it = 0\n",
    "    \n",
    "    # The FastICA algorithm\n",
    "    while lim > tol and it < maxit :\n",
    "        wx = W @ X1\n",
    "        gwx = g(wx,alpha)\n",
    "        g_wx = gprime(wx,alpha)\n",
    "        W1 = np.dot(gwx,X1.T)/X1.shape[1] - np.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "        W1 = sym_decorrelation(W1)\n",
    "        it = it +1\n",
    "        lim = np.max(np.abs(np.abs(np.diag(W1 @ W.T)) - 1.0))\n",
    "        W = W1\n",
    "\n",
    "    S = W @ X1\n",
    "    A = np.linalg.inv(W @ k)\n",
    "    X_re = A @ S\n",
    "    return{'X':X1.T,'X_re':X_re.T,'A':A.T,'S':S.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Source/fastICA_3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Source/fastICA_3.py\n",
    "import scipy.linalg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sym_decorrelation(W):\n",
    "    \"\"\" Symmetric decorrelation \"\"\"\n",
    "    K = np.dot(W, W.T)\n",
    "    s, u = np.linalg.eigh(K) \n",
    "    W = (u @ np.diag(1.0/np.sqrt(s)) @ u.T) @ W\n",
    "    return W\n",
    "\n",
    "def g_logcosh(wx,alpha):\n",
    "    \"\"\"derivatives of logcosh\"\"\"\n",
    "    return np.tanh(alpha * wx)\n",
    "def gprime_logcosh(wx,alpha):\n",
    "    \"\"\"second derivatives of logcosh\"\"\"\n",
    "    return alpha * (1-np.square(np.tanh(alpha*wx)))\n",
    "# exp\n",
    "def g_exp(wx,alpha):\n",
    "    \"\"\"derivatives of exp\"\"\"\n",
    "    return wx * np.exp(-np.square(wx)/2)\n",
    "def gprime_exp(wx,alpha):\n",
    "    \"\"\"second derivatives of exp\"\"\"\n",
    "    return (1-np.square(wx)) * np.exp(-np.square(wx)/2)\n",
    "\n",
    "\n",
    "def fastICA_3(X, f,alpha=None,n_comp=None,maxit=200, tol=1e-04):\n",
    "    \"\"\"FastICA algorithm for several units\"\"\"\n",
    "    n,p = X.shape\n",
    "    #check if n_comp is valid\n",
    "    if n_comp is None:\n",
    "        n_comp = min(n,p)\n",
    "    elif n_comp > min(n,p):\n",
    "        print(\"n_comp is too large\")\n",
    "        n_comp = min(n,p)\n",
    "       \n",
    "    #centering\n",
    "    #by subtracting the mean of each column of X (array).\n",
    "    X = X - X.mean(axis=0)[None,:]\n",
    "    X = X.T\n",
    " \n",
    "    #whitening\n",
    "    s = np.linalg.svd(X @ (X.T) / n)\n",
    "    D = np.diag(1/np.sqrt(s[1]))\n",
    "    k = D @ (s[0].T)\n",
    "    k = k[:n_comp,:]\n",
    "    X1 = k @ X\n",
    "   \n",
    "    # initial random weght vector\n",
    "    w_init = np.random.normal(size=(n_comp, n_comp))\n",
    "    W = sym_decorrelation(w_init)\n",
    " \n",
    "    lim = 1\n",
    "    it = 0\n",
    "   \n",
    "    # The FastICA algorithm\n",
    "    while lim > tol and it < maxit :\n",
    "        wx = W @ X1\n",
    "        if f ==\"logcosh\":\n",
    "            gwx = g_logcosh(wx,alpha)\n",
    "            g_wx = gprime_logcosh(wx,alpha)\n",
    "        elif f ==\"exp\":\n",
    "            gwx = g_exp(wx,alpha)\n",
    "            g_wx = gprimeg_exp(wx,alpha)\n",
    "        else:\n",
    "            print(\"doesn't support this approximation negentropy function\")\n",
    "        W1 = np.dot(gwx,X1.T)/X1.shape[1] - np.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "        W1 = sym_decorrelation(W1)\n",
    "        it = it +1\n",
    "        lim = np.max(np.abs(np.abs(np.diag(W1 @ W.T))) - 1.0)\n",
    "        W = W1\n",
    " \n",
    "    S = W @ X1\n",
    "    A = scipy.linalg.pinv2(W @ k)   \n",
    "    return{'X':X1.T,'A':A.T,'S':S.T}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Source/fastICA_scipy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Source/fastICA_scipy.py\n",
    "\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import numpy as np\n",
    "\n",
    "def sym_decorrelation_scipy(W):\n",
    "    \"\"\" Symmetric decorrelation \"\"\"\n",
    "    K = scipy.dot(W, W.T)\n",
    "    s, u = scipy.linalg.eigh(K) \n",
    "    W = scipy.dot(scipy.dot(scipy.dot(u,np.diag(1.0/np.sqrt(s)) ),u.T),W)\n",
    "    return W\n",
    "\n",
    "def fastICA_scipy(X, f,alpha=None, n_comp=None,maxit=200, tol=1e-04):\n",
    "    \"\"\"FastICA algorithm for several units\"\"\"\n",
    "    n,p = X.shape\n",
    "    #check if n_comp is valid\n",
    "    if n_comp is None:\n",
    "        n_comp = min(n,p)\n",
    "    elif n_comp > min(n,p):\n",
    "        print(\"n_comp is too large\")\n",
    "        n_comp = min(n,p)\n",
    "        \n",
    "    #centering\n",
    "    #by subtracting the mean of each column of X (array).\n",
    "    X = X - X.mean(axis=0)[None,:]\n",
    "    X = X.T\n",
    "\n",
    "    #whitening\n",
    "    svd = scipy.linalg.svd(scipy.dot(X,X.T) / n)\n",
    "    k = scipy.dot(np.diag(1/np.sqrt(svd[1])),svd[0].T)\n",
    "    k = k[:n_comp,:] \n",
    "    X1 = scipy.dot(k,X)\n",
    "    del X\n",
    "    \n",
    "    # approximation negentropy function\n",
    "    if f == \"logcosh\":\n",
    "        def g(wx,alpha):\n",
    "            return scipy.tanh(alpha * wx)\n",
    "        def gprime(wx,alpha):\n",
    "            return alpha * (1-np.square(scipy.tanh(alpha*wx)))\n",
    "    elif f == \"exp\":\n",
    "        def g(wx,alpha):\n",
    "            return wx * np.exp(-np.square(wx)/2)\n",
    "        def gprime(wx,alpha):\n",
    "            return (1-np.square(wx)) * np.exp(-np.square(wx)/2)\n",
    "    else:\n",
    "        print(\"doesn't support this approximation negentropy function\")\n",
    "               \n",
    "    # initial random weght vector\n",
    "    w_init = np.random.normal(size=(n_comp, n_comp))\n",
    "    W = sym_decorrelation_scipy(w_init)\n",
    "\n",
    "    lim = 1\n",
    "    it = 0\n",
    "    \n",
    "    # The FastICA algorithm\n",
    "    while lim > tol and it < maxit :\n",
    "        wx = scipy.dot(W,X1)\n",
    "        gwx = g(wx,alpha)\n",
    "        g_wx = gprime(wx,alpha)\n",
    "        W1 = scipy.dot(gwx,X1.T)/X1.shape[1] - scipy.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "        W1 = sym_decorrelation_scipy(W1)\n",
    "        it = it +1\n",
    "        lim = np.max(np.abs(np.abs(np.diag(scipy.dot(W1,W.T))) - 1.0))\n",
    "        W = W1\n",
    "\n",
    "    S = scipy.dot(W,X1)\n",
    "    A = scipy.linalg.pinv2(scipy.dot(W,k))\n",
    "    X_re = scipy.dot(A,S)\n",
    "    return{'X':X1.T,'X_re':X_re.T,'A':A.T,'S':S.T}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Source/fastICA_jit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Source/fastICA_jit.py\n",
    "\n",
    "import scipy.linalg\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def sym_decorrelation_jit(W):\n",
    "    \"\"\" Symmetric decorrelation \"\"\"\n",
    "    K = np.dot(W, W.T)\n",
    "    s, u = np.linalg.eigh(K) \n",
    "    W = (u @ np.diag(1.0/np.sqrt(s)) @ u.T) @ W\n",
    "    return W\n",
    "\n",
    "def g_logcosh_jit(wx,alpha):\n",
    "    \"\"\"derivatives of logcosh\"\"\"\n",
    "    return np.tanh(alpha * wx)\n",
    "def gprime_logcosh_jit(wx,alpha):\n",
    "    \"\"\"second derivatives of logcosh\"\"\"\n",
    "    return alpha * (1-np.square(np.tanh(alpha*wx)))\n",
    "# exp\n",
    "def g_exp_jit(wx,alpha):\n",
    "    \"\"\"derivatives of exp\"\"\"\n",
    "    return wx * np.exp(-np.square(wx)/2)\n",
    "def gprime_exp_jit(wx,alpha):\n",
    "    \"\"\"second derivatives of exp\"\"\"\n",
    "    return (1-np.square(wx)) * np.exp(-np.square(wx)/2)\n",
    "\n",
    "\n",
    "def fastICA_jit(X, f,alpha=None,n_comp=None,maxit=200, tol=1e-04):\n",
    "    \"\"\"FastICA algorithm for several units\"\"\"\n",
    "    n,p = X.shape\n",
    "    #check if n_comp is valid\n",
    "    if n_comp is None:\n",
    "        n_comp = min(n,p)\n",
    "    elif n_comp > min(n,p):\n",
    "        print(\"n_comp is too large\")\n",
    "        n_comp = min(n,p)\n",
    "       \n",
    "    #centering\n",
    "    #by subtracting the mean of each column of X (array).\n",
    "    X = X - X.mean(axis=0)[None,:]\n",
    "    X = X.T\n",
    " \n",
    "    #whitening\n",
    "    s = np.linalg.svd(X @ (X.T) / n)\n",
    "    D = np.diag(1/np.sqrt(s[1]))\n",
    "    k = D @ (s[0].T)\n",
    "    k = k[:n_comp,:]\n",
    "    X1 = k @ X\n",
    "   \n",
    "    # initial random weght vector\n",
    "    w_init = np.random.normal(size=(n_comp, n_comp))\n",
    "    W = sym_decorrelation_jit(w_init)\n",
    " \n",
    "    lim = 1\n",
    "    it = 0\n",
    "   \n",
    "    # The FastICA algorithm\n",
    "    while lim > tol and it < maxit :\n",
    "        wx = W @ X1\n",
    "        if f ==\"logcosh\":\n",
    "            gwx = g_logcosh_jit(wx,alpha)\n",
    "            g_wx = gprime_logcosh_jit(wx,alpha)\n",
    "        elif f ==\"exp\":\n",
    "            gwx = g_exp_jit(wx,alpha)\n",
    "            g_wx = gprimeg_exp_jit(wx,alpha)\n",
    "        else:\n",
    "            print(\"doesn't support this approximation negentropy function\")\n",
    "        W1 = np.dot(gwx,X1.T)/X1.shape[1] - np.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "        W1 = sym_decorrelation_jit(W1)\n",
    "        it = it +1\n",
    "        lim = np.max(np.abs(np.abs(np.diag(W1 @ W.T))) - 1.0)\n",
    "        W = W1\n",
    " \n",
    "    S = W @ X1\n",
    "    A = scipy.linalg.pinv2(W @ k)   \n",
    "    return{'X':X1.T,'A':A.T,'S':S.T}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numexpr\n",
    "\n",
    "note: numexpr can used only for element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Source/fastICA_ne.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Source/fastICA_ne.py\n",
    "\n",
    "import scipy.linalg\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "\n",
    "def sym_decorrelation_ne(W):\n",
    "    \"\"\" Symmetric decorrelation \"\"\"\n",
    "    K = np.dot(W, W.T)\n",
    "    s, u = np.linalg.eigh(K) \n",
    "    return (u @ np.diag(1.0/np.sqrt(s)) @ u.T) @ W\n",
    "# logcosh\n",
    "def g_logcosh_ne(wx,alpha):\n",
    "    \"\"\"derivatives of logcosh\"\"\"\n",
    "    return ne.evaluate('tanh(alpha * wx)')\n",
    "def gprime_logcosh_ne(wx,alpha):\n",
    "    \"\"\"second derivatives of logcosh\"\"\"\n",
    "    return alpha * (1-ne.evaluate('tanh(alpha*wx)**2'))\n",
    "# exp\n",
    "def g_exp_ne(wx,alpha):\n",
    "    \"\"\"derivatives of exp\"\"\"\n",
    "    return ne.evaluate('wx * exp(-wx**2/2)')\n",
    "def gprime_exp_ne(wx,alpha):\n",
    "    \"\"\"second derivatives of exp\"\"\"\n",
    "    return (1-np.square(wx)) * ne.evaluate('exp(-wx**2/2)')\n",
    "\n",
    "\n",
    "def fastICA_ne(X, f,alpha=None,n_comp=None,maxit=200, tol=1e-04):\n",
    "    n,p = X.shape\n",
    "    #check if n_comp is valid\n",
    "    if n_comp is None:\n",
    "        n_comp = min(n,p)\n",
    "    elif n_comp > min(n,p):\n",
    "        print(\"n_comp is too large\")\n",
    "        n_comp = min(n,p)\n",
    "       \n",
    "    #centering\n",
    "    #by subtracting the mean of each column of X (array).\n",
    "    X = X - X.mean(axis=0)[None,:]\n",
    "    X = X.T\n",
    " \n",
    "    #whitening\n",
    "    s = np.linalg.svd(X @ (X.T) / n)\n",
    "    D = np.diag(1/np.sqrt(s[1]))\n",
    "    k = D @ (s[0].T)\n",
    "    k = k[:n_comp,:]\n",
    "    X1 = k @ X\n",
    "   \n",
    "    # initial random weght vector\n",
    "    w_init = np.random.normal(size=(n_comp, n_comp))\n",
    "    W = sym_decorrelation_ne(w_init)\n",
    " \n",
    "    lim = 1\n",
    "    it = 0\n",
    "   \n",
    "    # The FastICA algorithm\n",
    "    while lim > tol and it < maxit :\n",
    "        wx = W @ X1\n",
    "        if f ==\"logcosh\":\n",
    "            gwx = g_logcosh_ne(wx,alpha)\n",
    "            g_wx = gprime_logcosh_ne(wx,alpha)\n",
    "        elif f ==\"exp\":\n",
    "            gwx = g_exp_ne(wx,alpha)\n",
    "            g_wx = gprimeg_exp_ne(wx,alpha)\n",
    "        else:\n",
    "            print(\"doesn't support this approximation negentropy function\")\n",
    "        W1 = np.dot(gwx,X1.T)/X1.shape[1] - np.dot(np.diag(g_wx.mean(axis=1)),W)\n",
    "        W1 = sym_decorrelation_ne(W1)\n",
    "        it = it +1\n",
    "        lim = np.max(np.abs(np.abs(np.diag(W1 @ W.T))) - 1.0)\n",
    "        W = W1\n",
    " \n",
    "    S = W @ X1\n",
    "    A = scipy.linalg.pinv2(W @ k)   \n",
    "    return{'X':X1.T,'A':A.T,'S':S.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
